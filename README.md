# Image-Captioning-LSTM
I made an image captioning model using LSTM and encoder-decoder architecture on the Flickr8k dataset. The model is made using keras framework and transformer is used to download 'bert-base-uncased' model to encode the result and compare it to the ground truth.
<br>

 <img src="/images/image1.jpg" alt="Alt text" title="Optional title" style="
  display: block;
  margin-left: 100px;
  width: 50%;">
  
 <img src="/images/image2.jpg" alt="Alt text" title="Optional title" style="
  display: block;
  margin-left: 100px;
  width: 50%;">


